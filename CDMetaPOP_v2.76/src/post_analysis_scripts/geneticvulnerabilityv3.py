# ------------------------------------------------------------------------------------------------
# v18 -- Dec 15, 2013: 
#   0. Added loci select option
# v17 -- Nov 27, 2013:
#	0. Added het to output file. 
# v16 -- Sept 04, 2013:
#	0. Found error in output adding nan.
# v15 -- July 23, 2013 Updates:
#   0. Changes code to reflect varying carrying capacity per subpopulation.
#	1. Change code to refelct fluctuating population sizes in each generation, update metrics.
# v14 -- Feb 22, 2013 Updates:
#	0. Add fake pop holders for indices 0 and 3 as well as 0 and 1 for metrics
#	1. Normalize M by N in population.
#	2. deltaN from intial time not previous time.
# v13 -- Dec 22, 2012 Fixation indices validated with diveRsity program - remove this section of
#	code.
#	Remove multiplicative code, cleanup...
#   Added Hedricks Gh and Ghfun.
# v12 -- Dec 20, 2012 Calculated fixation indices (Gst and D) with program diveRsity. Read in
#	from fixation indices files.
#	Correct Hs and Ht pairwise calculations to match Nei's 1973 gene diversity work.
# v11 -- Dec 7, 2012 Add bias and unbiased estimators.
#		Changed delta Fst abs(Fst_t-Fst_t0).
# v10 -- Dec 3, 2012 Added Jost D code (hopped 9 inbetween work)
# v8 -- Nov 19, 2012 Checking over calcs...
#		Removed if 0 pop, Fst should be 1 -> Fst should be NA, then 
#			recalculate mean, be careful of nans
#		Missmatch in alleles grabbing from output file - calculate from 
#			grid file.
#		Also calculate population here too.
# v7 -- Drop subpopulations from Fst calculation if 0 abundance.
# v6 -- Added rate of change in case time frame is greater than 1 year. 
#		Also, alleles could be 0 and therefor a negative 1 shows up. FIx all negatives to 0.
#		And if 0 population, Fst should be 1?
# v5 -- Add average pairwise Fst here. Remove Dst.
# v4 -- Corrected Nm rescale to carrying capacity. This version does not use Petit. Just
#	counts up alleles. Jost Dst read in from file. and same demographics.
# v3 -- Read in PetitAllelicRichness index, added Jost's Dst. Note need to run 
#	PetitAllelicRichnessv0.py script first.
# v2 -- Added multiple generations
# v1 -- Added monte carlo mean, CIs
# v0 -- Initial script -> psuedo code
# cdfish_geneticvulnerability.py
# geneticvulnerabilty.py
# v0 - Convert cdfish code to cdmetapop code, read in XY,K,N from patchvars.csv file
# v1 - Add -9999 values in patches that have no individuals to output so that ARCgis will easily display.
# v2 - Add in option for grid and gridSample files.
# v3 and v4 - working on getting compatible with arcgis output.
# v5 - New version can have N greater than K and no NA values. Updated K values, but still normalize abundance by defined K - so this value is still needed. Also cleaned up some misc np labeling.
# v6 - This version allows you to read in a file with defined regroups patch/populations. Provide a switch option to use K_Pops for K values or use the n K values.
# v7,v099 - Update version for cdmetapop output v0.99.02. Unique Pops now split up by genes initial file
# v1.00 - Update version for cdmetapop outpu v1.00. 
# v09912 - Error in genes read in when patches are empty.
# v1.08 - Updated version for current cdmetapop runs. Included check for crashing populations in 
# which no file exists for given year.
# v2 - Fixed some bugs for when craching pops happen. naming convention now does not apply to program version. 
# v3 - Updated to newest version. Added batchno option.
# Author: Erin L Landguth
# Created: May 22 2011
# Updated: Jan 2017
# ------------------------------------------------------------------------------------------------

# Import statements
try:
	import numpy as np 
	from numpy.random import *
except ImportError:
	raise ImportError, "Numpy required."				
import pdb,os,copy,sys		
from random import *

# Functions needed
def count_unique(keys):
    uniq_keys = np.unique(keys)
    bins = uniq_keys.searchsorted(keys)
    return uniq_keys, np.bincount(bins)
	
#-----------------
# User Input
#-----------------

# Switch for special project Casey Day: True or False
forCD = False

dir = "D:/projects/CDmetaPOP/Seattle/Runs/data_WCT1043_BarrierRemovalwGenetics/Compare_Landscapes/"

# Outputname 
outname = "ChangingBarriers"
outdir = dir+"summary_GV/"

# Location and name for xy, K,N
xyfilename = "D:/projects/CDmetaPOP/Seattle/Runs/data_WCT1043_BarrierRemovalwGenetics/PatchVars1043_Model0_Kmodv3.csv"


# Number of monte carlo runs
mcruns = 2
# POint to the batch number 
batchno = 2

# Generation to extract A from
#gen = [0,24,25,34,35,36,37,38,39,40,50,60,70,80,90,100,125]
#gen = [0,25,35,40,50,70,90,125]
#gen = [25,35,40,90,0,50,70]
#gen = [0,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,199]
gen = np.asarray([51,57,59,64,65,66,69,71,90])
gen = xrange(51,91,1)

# Number of patches
n = 1043
# Use these patches (N) or defined K_Pops (Y)
Kpopanswer = 'Y'

# If 'Y' K_Pops then get XY coord file for the order of the genesint, ignore this otherwise.
xycoords = xyfilename

# Number of alleles - for normalizing the allele diversity
loci = 19
alleles = 36

# Which grid files to do ind{}.csv or indSample{}.csv (ind or indSample)
gridformat = 'ind'

# Sample the loci to run analysis on (for loci under selection)
#selloci = xrange(1,20)
#selloci = xrange(0,1)
selloci = xrange(loci)

# Calculate each statistic - Error (use qnorm(0.975)=1.959964 - couldn't find equivalent qnorm) 
qnorm = 1.959964

# ------------------
# End User Input
# ------------------

# List folders in this dir
def listdirs(folder):
    return [d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder)) if os.path.isdir(d)]
folderList = listdirs(dir)

# Number of initial alleles
maxA = len(selloci)*alleles
alleles = alleles*np.ones(loci,int)

#-----------------------------------------------
# Initial File IO - read in cost distance values
#-----------------------------------------------	
# Open file to extract XY values
xyinputfile = open(xyfilename,'r')

# Read lines from the file
lines = xyinputfile.readlines()

#Close the file
xyinputfile.close()

# Create an empty matrix to append to
xyvalues = []

# Split up each line in file and append to empty matrix for generation specified
for i in xrange(len(lines)):
	thisline = lines[i].split(',')
	xyvalues.append(thisline)

# Get x and y values
X = []
Y = []
K = []
Pops = []
Patch = []
for i in xrange(len(xyvalues)-1):
	X.append(float(xyvalues[i+1][1]))
	Y.append(float(xyvalues[i+1][2]))
	K.append(int(xyvalues[i+1][4]))
	Pops.append(xyvalues[i+1][9])
	Patch.append(int(xyvalues[i+1][0]))

# Switch to use n patches or defined K_pops
if Kpopanswer == 'Y':
	# Get unique number of pops
	unique_Pops = count_unique(Pops)
	
	# Then get the K for each of these pops
	K_Pops = []
	K_Pops_Patchnos = []
	for i in unique_Pops[0]:
		index = np.where(np.asarray(Pops) == i)[0]
		K_Pops.append(sum(np.asarray(K)[index]))
		# Get the Patch numbers that are part of this pop
		K_Pops_Patchnos.append(np.asarray(Patch)[index])
		
	# Redefine new K numbers and number of populations here...careful of ordering throughout
	K = K_Pops # This is ordered 1 to ...
	n = len(unique_Pops[0])
	
	# Update XY - crude temp way for right now
	X_temp = []
	Y_temp = []
	for i in unique_Pops[0]:
		index = np.where(np.asarray(Pops) == i)[0]
		# sample a random index
		rand_index = sample(index,1)[0]
		X_temp.append(X[rand_index])
		Y_temp.append(Y[rand_index])
		
	X = X_temp
	Y = Y_temp
	'''
	# Update XY - One way with specified file that matches Pops
	# Open file to extract XY values
	xyinputfile = open(xycoords,'r')

	# Read lines from the file
	lines = xyinputfile.readlines()
	
	#Close the file
	xyinputfile.close()

	# Create an empty matrix to append to
	xyvalues = []

	# Split up each line in file and append to empty matrix for generation specified
	for i in xrange(len(lines)):
		thisline = lines[i].split(',')
		xyvalues.append(thisline)

	# Get x and y values
	X = []
	Y = []
	for i in xrange(len(xyvalues)-1):
		X.append(float(xyvalues[i+1][1]))
		Y.append(float(xyvalues[i+1][2]))
	'''
# Delete lines
del(lines)

# --------------------
# Begin gen loop
# --------------------
for igen in xrange(len(gen)):
	
	# ----------------------------	
	#  Preliminary vector storage
	# ----------------------------
	# All information
	He = []
	population = []
	Population = []
	A = []
	Alleles = []
	strayer = []
	Nm = []
	abundance = []
	HS = []
	F = []
	HT = []
	D = []
	Fun = []
	Dun = []
	G = []
	Gun = []

	# Mean storage variable
	He_mean = []	
	population_mean = []
	Population_mean = []
	A_mean = []
	strayer_mean = []
	Nm_mean = []
	deltaF_mean = []
	deltaD_mean = []
	deltaFun_mean = []
	deltaDun_mean = []
	deltaGun_mean = []
	abundance_mean = []
	deltaAbund_mean = []
	F_mean = []
	D_mean = []
	Fun_mean = []
	Dun_mean = []
	G_mean = []
	Gun_mean = []

	# SD storage variable
	He_sd = []
	population_sd = []
	A_sd = []
	strayer_sd = []
	Nm_sd = []
	abundance_sd = []
	F_sd = []
	D_sd = []
	Fun_sd = []
	Dun_sd = []
	G_sd = []
	Gun_sd =[]

	# Left CI storage variable
	He_left = []
	population_left = []
	A_left = []
	strayer_left = []
	Nm_left = []
	deltaF_left = []
	deltaD_left = []
	deltaFun_left = []
	deltaDun_left = []
	deltaGun_left = []
	abundance_left = []
	deltaAbund_left = []
	F_left = []
	D_left = []
	Fun_left = []
	Dun_left = []
	G_left = []
	Gun_left = []
	
	# Right CI storage variable
	He_right = []
	population_right = []
	A_right = []
	strayer_right = []
	Nm_right = []
	deltaF_right = []
	deltaD_right = []
	deltaFun_right = []
	deltaDun_right = []
	deltaGun_right = []
	abundance_right = []
	deltaAbund_right = []
	F_right = []
	D_right = []
	Fun_right = []
	Dun_right = []
	G_right = []
	Gun_right = []
	
	# -----------------------------------	
	# 3. Read in and store metrics
	# -----------------------------------
	# Loop over folders
	#for imc in xrange(len(folderList)): 
	for imc in xrange(mcruns):

		# Add a batch spot to the vectors
		strayer.append([])
		Nm.append([])
		abundance.append([])
		F.append([])
		D.append([])
		Fun.append([])
		Dun.append([])
		G.append([])
		Gun.append([])
					
		# --------------------------
		#  Read in information 
		# --------------------------		
			
		# Open file to extract number of migrants
		#if forCD:
		#	filename = dir+"/batchrun"+str(batchno)+"mcrun0/"+gridformat+str(gen[igen])+".csv"
		#else:
		#	filename = dir+"/"+gridformat+str(gen[igen])+".csv"	
		filename = dir+"/batchrun"+str(batchno)+"mcrun0/"+gridformat+str(gen[igen])+".csv"
		
		# Check to see if file exists
		try:				
			xyinputfile = open(filename,'r')
					
			# Read lines from the file
			lines = xyinputfile.readlines()

			#Close the file
			xyinputfile.close()

			# Create an empty matrix to append to
			x = []

			# Split up each line in file and append to empty matrix for generation specified
			for i in xrange(len(lines)):
				thisline = lines[i].split(',')
				x.append(thisline)
			
			N = [] # The actual number of individuals that showed up 
			# Extract values from this grid	
			for i in xrange(len(x)-1):
				strayer[imc].append(str(x[i+1][3]))
				N.append(int(x[i+1][0]))
			N_Patch = count_unique(N)[0] # The unique number of patches that are populated
			N_Pop = count_unique(N)[1] # The number in each patch
			
			# Get the index into x for genes for each patch
			if Kpopanswer == 'N':
				N_Pop_Index = []
				temp_N_Pop = [] # update N_Pop for full n
				for i in range(1,n+1):
					indexHere = np.where(np.asarray(N) == i)[0]
					N_Pop_Index.append(indexHere)
					temp_N_Pop.append(len(indexHere))
				N_Pop = temp_N_Pop
				
			# If the defined population switch is on then get the corrected numbers - careful of indexing		
			if Kpopanswer == 'Y':
				temp_N_Pop = []
				temp_N_Patch = []
				temp_K_Pops_Patchnos = []
				N_Pop_Index = []
				for i in xrange(n):
					index = K_Pops_Patchnos[i] # ie Pop 1 corresponds to Patch #s 57, 58,...
					index = set(index)
					# The actual Patch #s that showed up that are still labeled Pop 1
					indexHere = [j for j,item in enumerate(N_Patch) if item in index]
					temp_K_Pops_Patchnos.append(indexHere) 
					# Then index into N_Pop and sum for the redefined population
					if len(indexHere) == 0:
						temp_N_Pop.append(0)
					else:
						temp_N_Pop.append(sum(N_Pop[indexHere]))
						temp_N_Patch.append(i+1)
					# Get the x index for genes later
					indexHere_inN = [j for j,item in enumerate(N) if item in index]
					N_Pop_Index.append(indexHere_inN)
					
				N_Pop = temp_N_Pop
							
			# --------------------------------------------
			# Read in genotypes to get pairwise FST values
			# --------------------------------------------
					
			# Create pairwise list and other gene variables
			all_freq_sub = []
			subgridtotal = []
			all_freq_sq_sub = []
			all_freq_pairs = []
			all_freq_sq_pairs = []
			het_sub = []
			het_pairs = []
			Ji = []
			Jij = []
			Dij = []
			genes = []
			for i in xrange(n):
				all_freq_sub.append([])
				subgridtotal.append([])	
				all_freq_sq_sub.append([])
				het_sub.append([])
				het_pairs.append([])
				all_freq_pairs.append([])
				all_freq_sq_pairs.append([])
				Ji.append([])
				Jij.append([])
				Dij.append([])
				genes.append([])
					
			# Store genetic information: genes[subpop][individual][loci][alleles]
			for i in xrange(len(N_Pop)): # Index start at 1 to check Patch number 1 to n + 1
				if N_Pop[i] == 0: # check if the pop exists
					genes[i].append([])
					for k in selloci:
						genes[i][0].append(np.nan*np.ones((alleles[k])))
					continue
				else:
					for jind in xrange(N_Pop[i]):                        
						spotj = N_Pop_Index[i][jind]
						genes[i].append([])
						for k in selloci:
							if forCD: # Here check for old version
								temp = x[1+spotj][14+(k*alleles[k]):14+(k*alleles[k])+alleles[k]]
							else: # Here is most recent version
								temp = x[1+spotj][17+(k*alleles[k]):17+(k*alleles[k])+alleles[k]]
							temp[-1] = temp[-1].strip('\n')
							genes[i][jind].append(np.asarray(temp,dtype='float'))
			subgridtotal = N_Pop
					
			#---------------------
			# Get population here
			population.append(np.insert(subgridtotal,0,np.nansum(subgridtotal)))
					
			# Cast genes as an numpy array as byte type
			#genes_array_woNA = np.asarray(genes,dtype='float')
			#genes_array = np.asarray(genes)
			genes_array = genes
			
			# Get allele location as seqence from alleles array
			allele_numbers = []
			for i in selloci:
				for j in xrange(alleles[i]):
					allele_numbers.append(j)
			allele_numbers = np.asarray(allele_numbers)
			# The total number of alleles
			total_alleles = len(allele_numbers)
			
			# Get allele frequency for subpopulations and homozygosity
			for i in xrange(n):
				all_freq_sub[i].append(np.nansum(np.asarray(genes_array[i][:][:],dtype='float'),axis=0).reshape(total_alleles))
				all_freq_sub[i] = all_freq_sub[i][0]/(2.*subgridtotal[i])
				all_freq_sq_sub[i].append(all_freq_sub[i]**2) 
				Ji[i].append(np.nansum(all_freq_sq_sub[i][0])/len(selloci)) # This is Nei's gene identity of ith subpopulation (homog) averaged per locus
				het_sub[i].append(1. - Ji[i][0])	# Will be nan if no individuals in that sub		
				# Next loop through pairwise subpopulations
				for ipair in xrange(n):
					all_freq_pairs[i].append([])
					all_freq_sq_pairs[i].append([])
					het_pairs[i].append([])
					Jij[i].append([])
					# If there are individuals in both subpops
					if subgridtotal[i] != 0 and subgridtotal[ipair] != 0:	
						# Get genes for each populations - convert to frequency of allele in ith subpop
						i_allsum = np.nan_to_num(np.nansum(np.asarray(genes_array[i][:][:],dtype='float'),axis=0))/(2.*subgridtotal[i])
						ipair_allsum = np.nan_to_num(np.nansum(np.asarray(genes_array[ipair][:][:],dtype='float'),axis=0))/(2.*subgridtotal[ipair])
						Jij[i][ipair].append(np.nansum(i_allsum*ipair_allsum)/len(selloci)) # This is Nei's gene identity b/w ith and jth subpopulation
						all_freq_pairs[i][ipair].append((i_allsum+ipair_allsum).reshape(total_alleles)) # Not correct, but not used...
						all_freq_pairs[i][ipair] = all_freq_pairs[i][ipair][0]/(2.*(subgridtotal[i]+subgridtotal[ipair])) # Not correct, but not used...
						all_freq_sq_pairs[i][ipair].append(all_freq_pairs[i][ipair]**2)
						
						het_pairs[i][ipair].append(1. - Jij[i][ipair][0])
					# If there are no individuals in both pairs, then make nan
					else:
						all_freq_pairs[i][ipair].append(np.nan)
						all_freq_sq_pairs[i][ipair].append(np.nan)
						het_pairs[i][ipair].append(np.nan)
						Jij[i][ipair].append(np.nan)
			
			# This is Nei's gene diversity b/w ith and jth subpopultion
			for i in xrange(n):
				for ipair in xrange(n):
					Dij[i].append([])
					Dij[i][ipair].append(((Ji[i][0]+Ji[ipair][0])/2)-Jij[i][ipair][0]) 
					
			# ---------------------------
			# Get allelic diversity here
			alleles_sub = []
			# Get the total number of alleles in each subpop - allelic diversity
			for i in xrange(n):
				alleles_sub.append((np.array(all_freq_sub[i]>0.).sum()-1)/float(maxA-1))
			A.append(alleles_sub)
			# Add het numbers
			He.append(np.transpose(het_sub)[0])
			
			# Replace het nan values with 0.0
			het_pairs = np.nan_to_num(het_pairs)
			het_sub = np.nan_to_num(het_sub)
			Dij = np.nan_to_num(Dij)
			
			#-----------------------
			# Extract metrics
			#-----------------------		
			# Iterate over subpopulations
			for i in xrange(n):	
			
				# ------------------------
				# Calculate abundance here
				# ------------------------
				if K[i] == 0:
					abundance[imc].append(float(population[imc][i+1])/1.)
				else:
					abundance[imc].append(float(population[imc][i+1])/K[i])
				
				# ------------------------------------
				# Calculate Fst/D here: pairwise Fst/D
				# ------------------------------------
				# Only run Fst if abundance is not 0
				if abundance[imc][i] != 0.0:
					Ftemp = []
					Dtemp = []
					Gtemp = []
					Funtemp = []
					Duntemp = []
					Guntemp = []
					for ipair in xrange(n):					
						# Don't calculate Ftemp for same i and ipair or if abundance is 0
						if i != ipair and population[imc][ipair+1] != 0:					
							
							# Hs and Ht
							HST = 1. - ((Ji[i][0] + Ji[ipair][0])/2)
							HTT = 1. - (((Ji[i][0] + Ji[ipair][0])/2.) - ((Dij[i][i][0]+Dij[i][ipair][0]+Dij[ipair][i][0]+Dij[ipair][ipair][0])/2.**2))
							
							# Ntilde harmonic mean
							temp1 = 1./population[imc][i+1]
							temp2 = 1./population[imc][ipair+1]
							Ntilde = 2./(temp1+temp2)
							
							# Hs and Ht hat estimators
							HeSestT = ((2.*Ntilde)/(2.*Ntilde-1))*HST
							HeTestT = (HTT+((HeSestT)/(2.*Ntilde*2)))					
							
							Funtemp.append((HeTestT-HeSestT)/HeTestT)					
							Duntemp.append((((HeTestT - HeSestT) / (1-HeSestT)) * (2. / (2-1))))
							Guntemp.append((((HeTestT-HeSestT)/HeTestT)*(2.-1+HeSestT)) / ((2.-1)*(1-HeSestT)))
							Ftemp.append((HTT-HST)/HTT)					
							Dtemp.append((((HTT - HST) / (1.-HST)) * (2. / (2-1))))
						
					# Get average Fst pairwise here (n-1 average pairs)
					Fun[imc].append(np.nansum(Funtemp)/(len(Funtemp)))
					F[imc].append(np.nansum(Ftemp)/(len(Ftemp)))						
					# Get average D pairwise here (n-1 average pairs)
					Dun[imc].append(np.nansum(Duntemp)/len(Duntemp))
					D[imc].append(np.nansum(Dtemp)/len(Dtemp))
					Gun[imc].append(np.nansum(Guntemp)/len(Guntemp))
					
				# If abundance is 0 for that subpopulation, make F == nan
				if abundance[imc][i] == 0.0:
					F[imc].append(np.nan)
					D[imc].append(np.nan)
					Fun[imc].append(np.nan)
					Dun[imc].append(np.nan)
					Gun[imc].append(np.nan)
					# Make A nan also
					A[imc][i] = np.nan
					He[imc][i] = np.nan
								
				#--------------------------
				# Get number of immigrants
				#--------------------------
				Nm[imc].append([])
				for j in xrange(subgridtotal[i]):
					spotj = N_Pop_Index[i][j]
					if 'S' in strayer[imc][spotj][0:5] or 'Z' in strayer[imc][spotj][0:5]:
						Nm[imc][i].append(1)
						
				# If abundance is 0 for that subpopulation, make nan
				if abundance[imc][i] == 0.0:
					Nm[imc][i] = np.nan
				else:
					# Here normalize by abundance in that population (used to be K).
					Nm[imc][i] = float(len(Nm[imc][i])) / (abundance[imc][i] * K[i])

		
		# If file does not exist
		except (IOError,OSError) as e:
			print("Load file: %s the file (%s) is not available!"%(e,filename))
			print("Including highest vulnerability metrics for this year.")
			# Then add nan or 0 values
			# Iterate over subpopulations
			A.append([]) # Add mc spot
			He.append([]) # Add mc spot
			for i in xrange(n):
				Nm[imc].append(np.nan)
				abundance[imc].append(0.0)
				F[imc].append(np.nan)
				D[imc].append(np.nan)
				Fun[imc].append(np.nan)
				Dun[imc].append(np.nan)
				Gun[imc].append(np.nan)
				A[imc].append(np.nan)
				He[imc].append(np.nan)
			#He.append([np.zeros(n)*np.nan])
			# OTher numbers to keep the loops in sync
			subgridtotal = np.zeros((n)).tolist()
			population.append(np.insert(subgridtotal,0,np.nansum(subgridtotal)))
			
						
	# Turn into numpy arrays
	Nm = np.asarray(Nm)
	abundance = np.asarray(abundance)
	# Now make 0 abundance nan
	abundance[np.where(abundance == 0.0)] = np.nan
	F = np.asarray(F)
	D = np.asarray(D)
	Fun = np.asarray(Fun)
	Dun = np.asarray(Dun)
	Gun = np.asarray(Gun)
	A = np.asarray(A)
	# Negative A values (means 0 population), turn to nan CAREFULLL!!!!! is this always the case
	A[np.where(A <= 0.)[0]] = np.nan
	He = np.asarray(He)
	He[np.where(He <= 0.)[0]] = np.nan
		
	# ----------------------------------------------------------------------------------	
	# Calculate mean, sd, and confidence intervals for each subpopulation across each MC 
	# ----------------------------------------------------------------------------------	
	# Looptime Loop begin
	for imc in xrange(n):
		
		# Calculate each statistic - Mean
		Nm_mean.append(np.ma.average(np.ma.masked_invalid(Nm[:,imc])))
		abundance_mean.append(np.ma.average(np.ma.masked_invalid(abundance[:,imc])))
		F_mean.append(np.ma.average(np.ma.masked_invalid(F[:,imc])))
		D_mean.append(np.ma.average(np.ma.masked_invalid(D[:,imc])))
		Fun_mean.append(np.ma.average(np.ma.masked_invalid(Fun[:,imc])))
		Dun_mean.append(np.ma.average(np.ma.masked_invalid(Dun[:,imc])))
		Gun_mean.append(np.ma.average(np.ma.masked_invalid(Gun[:,imc])))
		A_mean.append(np.ma.average(np.ma.masked_invalid(A[:,imc])))
		He_mean.append(np.ma.average(np.ma.masked_invalid(He[:,imc])))
		
		# SD storage variable
		Nm_sd.append(np.ma.std(np.ma.masked_invalid(Nm[:,imc]))) 
		abundance_sd.append(np.ma.std(np.ma.masked_invalid(abundance[:,imc])))
		F_sd.append(np.ma.std(np.ma.masked_invalid(F[:,imc])))
		D_sd.append(np.ma.std(np.ma.masked_invalid(D[:,imc])))
		Fun_sd.append(np.ma.std(np.ma.masked_invalid(Fun[:,imc])))
		Dun_sd.append(np.ma.std(np.ma.masked_invalid(Dun[:,imc])))
		Gun_sd.append(np.ma.std(np.ma.masked_invalid(Gun[:,imc])))
		A_sd.append(np.ma.std(np.ma.masked_invalid(A[:,imc])))
		He_sd.append(np.ma.std(np.ma.masked_invalid(He[:,imc])))

		# Calculate each statistic - Error (use qnorm(0.975)=1.959964 - couldn't find equivalent qnorn) 
		Nm_error = qnorm*Nm_sd[imc]/np.sqrt(mcruns)
		abundance_error = qnorm*abundance_sd[imc]/np.sqrt(mcruns)
		F_error = qnorm*F_sd[imc]/np.sqrt(mcruns)
		D_error = qnorm*D_sd[imc]/np.sqrt(mcruns)
		Fun_error = qnorm*Fun_sd[imc]/np.sqrt(mcruns)
		Dun_error = qnorm*Dun_sd[imc]/np.sqrt(mcruns)
		Gun_error = qnorm*Gun_sd[imc]/np.sqrt(mcruns)
		A_error = qnorm*A_sd[imc]/np.sqrt(mcruns)
		He_error = qnorm*He_sd[imc]/np.sqrt(mcruns)

		# Left CI storage variable
		Nm_left.append(Nm_mean[imc]-Nm_error)
		abundance_left.append(abundance_mean[imc]-abundance_error)
		F_left.append(F_mean[imc]-F_error)
		D_left.append(D_mean[imc]-D_error)
		Fun_left.append(Fun_mean[imc]-Fun_error)
		Dun_left.append(Dun_mean[imc]-Dun_error)
		Gun_left.append(Gun_mean[imc]-Gun_error)
		A_left.append(A_mean[imc]-A_error)
		He_left.append(He_mean[imc]-He_error)
		
		# Right CI storage variable
		Nm_right.append(Nm_mean[imc]+Nm_error)
		abundance_right.append(abundance_mean[imc]+abundance_error)
		F_right.append(F_mean[imc]+F_error)
		D_right.append(D_mean[imc]+D_error)
		Fun_right.append(Fun_mean[imc]+Fun_error)
		Dun_right.append(Dun_mean[imc]+Dun_error)
		Gun_right.append(Gun_mean[imc]+Gun_error)
		A_right.append(A_mean[imc]+A_error)
		He_right.append(He_mean[imc]+He_error)
		
		# -----------------------------------------------
		# Calculate change in abundance and change in Fst
		# -----------------------------------------------
		# For deltaF and deltaAbund
		if igen == 0:
			deltaF_mean.append(0.0)
			deltaF_right.append(0.0)
			deltaF_left.append(0.0)
			deltaD_mean.append(0.0)
			deltaD_right.append(0.0)
			deltaD_left.append(0.0)
			deltaFun_mean.append(0.0)
			deltaFun_right.append(0.0)
			deltaFun_left.append(0.0)
			deltaDun_mean.append(0.0)
			deltaDun_right.append(0.0)
			deltaDun_left.append(0.0)
			deltaGun_mean.append(0.0)
			deltaGun_right.append(0.0)
			deltaGun_left.append(0.0)
			deltaAbund_mean.append(0.0)
			deltaAbund_right.append(0.0)
			deltaAbund_left.append(0.0)
			
		else:
			deltaF_mean.append(abs(F_mean[imc]-F0_mean[imc]))
			deltaF_right.append(abs(F_right[imc]-F0_right[imc]))
			deltaF_left.append(abs(F_left[imc]-F0_left[imc]))
			deltaD_mean.append(abs(D_mean[imc]-D0_mean[imc]))
			deltaD_right.append(abs(D_right[imc]-D0_right[imc]))
			deltaD_left.append(abs(D_left[imc]-D0_left[imc]))
			deltaFun_mean.append(abs(Fun_mean[imc]-Fun0_mean[imc]))
			deltaFun_right.append(abs(Fun_right[imc]-Fun0_right[imc]))
			deltaFun_left.append(abs(Fun_left[imc]-Fun0_left[imc]))
			deltaDun_mean.append(abs(Dun_mean[imc]-Dun0_mean[imc]))
			deltaDun_right.append(abs(Dun_right[imc]-Dun0_right[imc]))
			deltaDun_left.append(abs(Dun_left[imc]-Dun0_left[imc]))
			deltaGun_mean.append(abs(Gun_mean[imc]-Gun0_mean[imc]))
			deltaGun_right.append(abs(Gun_right[imc]-Gun0_right[imc]))
			deltaGun_left.append(abs(Gun_left[imc]-Gun0_left[imc]))
			
			deltaAbund_mean.append((abundance_mean[imc]-abund0_mean[imc]))
			deltaAbund_right.append((abundance_right[imc]-abund0_right[imc]))
			deltaAbund_left.append((abundance_left[imc]-abund0_left[imc]))
			# Condition where population was extinct (nan) in previous generation - check
			if abundance_mean[imc] == np.nan:
				pdb.set_trace()
			# Piecewise scale here - if abundance goes up that is good! Make 0
			if deltaAbund_mean[imc] > 0.0:
				deltaAbund_mean[imc] = 0.0
				deltaAbund_right[imc] = 0.0
				deltaAbund_left[imc] = 0.0		
						
	#---------------
	# Weight values
	#---------------
	weightGvalues_meanF = []
	weightGvalues_leftF = []
	weightGvalues_rightF = []
	weightDvalues_mean = []
	weightDvalues_left = []
	weightDvalues_right = []
	weightGvalues_meanD = []
	weightGvalues_leftD = []
	weightGvalues_rightD = []
	weightGvalues_meanFun = []
	weightGvalues_leftFun = []
	weightGvalues_rightFun = []
	weightGvalues_meanDun = []
	weightGvalues_leftDun = []
	weightGvalues_rightDun = []
	weightGvalues_meanGun = []
	weightGvalues_leftGun = []
	weightGvalues_rightGun = []
	subpop = []
	combinedF = []
	averagedF = []
	averagedD = []	
	averagedFun = []
	averagedDun = []
	averagedGun = []
			
	for i in xrange(n):		
		# Additive with F
		val = (-A_mean[i]+1) + F_mean[i] + (deltaF_mean[i]) 
		weightGvalues_meanF.append(val)
		val = (-A_left[i]+1) + F_left[i] + (deltaF_left[i]) 
		weightGvalues_leftF.append(val)
		val = (-A_right[i]+1) + F_right[i] + (deltaF_right[i]) 
		weightGvalues_rightF.append(val)
		val = (-abundance_mean[i]+1) + (-Nm_mean[i]+1) + (-deltaAbund_mean[i])
		weightDvalues_mean.append(val)
		val = (-abundance_left[i]+1) + (-Nm_left[i]+1) + (-deltaAbund_left[i])
		weightDvalues_left.append(val)
		val = (-abundance_right[i]+1) + (-Nm_right[i]+1) + (-deltaAbund_right[i])
		weightDvalues_right.append(val)
		subpop.append(i+1)
		combinedF.append(weightGvalues_meanF[i]+ weightDvalues_mean[i])
		averagedF.append((weightGvalues_meanF[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with D
		val = (-A_mean[i]+1) + D_mean[i] + (deltaD_mean[i]) 
		weightGvalues_meanD.append(val)
		val = (-A_left[i]+1) + D_left[i] + (deltaD_left[i]) 
		weightGvalues_leftD.append(val)
		val = (-A_right[i]+1) + D_right[i] + (deltaD_right[i]) 
		weightGvalues_rightD.append(val)
		averagedD.append((weightGvalues_meanD[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with F unbiased
		val = (-A_mean[i]+1) + Fun_mean[i] + (deltaFun_mean[i]) 
		weightGvalues_meanFun.append(val)
		val = (-A_left[i]+1) + Fun_left[i] + (deltaFun_left[i]) 
		weightGvalues_leftFun.append(val)
		val = (-A_right[i]+1) + Fun_right[i] + (deltaFun_right[i]) 
		weightGvalues_rightFun.append(val)
		averagedFun.append((weightGvalues_meanFun[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with D unbiased
		val = (-A_mean[i]+1) + Dun_mean[i] + (deltaDun_mean[i]) 
		weightGvalues_meanDun.append(val)
		val = (-A_left[i]+1) + Dun_left[i] + (deltaDun_left[i]) 
		weightGvalues_leftDun.append(val)
		val = (-A_right[i]+1) + Dun_right[i] + (deltaDun_right[i]) 
		weightGvalues_rightDun.append(val)
		averagedDun.append((weightGvalues_meanDun[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with G' unbiased
		val = (-A_mean[i]+1) + Gun_mean[i] + (deltaGun_mean[i]) 
		weightGvalues_meanGun.append(val)
		val = (-A_left[i]+1) + Gun_left[i] + (deltaGun_left[i]) 
		weightGvalues_leftGun.append(val)
		val = (-A_right[i]+1) + Gun_right[i] + (deltaGun_right[i]) 
		weightGvalues_rightGun.append(val)
		averagedGun.append((weightGvalues_meanGun[i]+ weightDvalues_mean[i])/2.)
		
	# ----------------------
	# Output to file
	#-----------------------

	# Create file to write info to
	outputfile = open(outdir+'vuln_summary'+outname+str(gen[igen])+'.csv','w')

	# Write out the titles
	# Add Titles from xypoints
	outputtitle = ['Subpopulation','X','Y',\
	'He_Mean','He_Left','He_Right',\
	'ADiv_Mean','ADiv_Left','ADiv_Right',\
	'G_Mean','G_Left','G_Right',\
	'deltaG_Mean','deltaG_Left','deltaG_Right',\
	'D_Mean','D_Left','D_Right',\
	'deltaD_Mean','deltaD_Left','deltaD_Right',\
	'Gest_Mean','Gest_Left','Gest_Right',\
	'deltaGest_Mean','deltaGest_Left','deltaGest_Right',\
	'Dest_Mean','Dest_Left','Dest_Right',\
	'deltaDest_Mean','deltaDest_Left','deltaDest_Right',\
	'Ghedest_Mean','Ghedest_Left','Ghedest_Right',\
	'deltaGhedest_Mean','deltaGhedest_Left','deltaGhedest_Right',\
	'Abundance_Mean','Abundance_Left','Abundance_Right',\
	'Nm_Mean','Nm_Left','Nm_Right',\
	'deltaAbund_Mean','deltaAbund_Left','deltaAbund_Right',\
	'DemoIndex_Mean_add','DemoIndex_Left_add','DemoIndex_Right_add',
	'GeneticIndex_Mean_add_G','GeneticIndex_Left_add_G','GeneticIndex_Right_add_G',\
	'GeneticIndex_Mean_add_D','GeneticIndex_Left_add_D','GeneticIndex_Right_add_D',\
	'GeneticIndex_Mean_add_Gest','GeneticIndex_Left_add_Gest','GeneticIndex_Right_add_Gest',\
	'GeneticIndex_Mean_add_Dest','GeneticIndex_Left_add_Dest','GeneticIndex_Right_add_Dest',\
	'GeneticIndex_Mean_add_Ghedest','GeneticIndex_Left_add_Ghedest','GeneticIndex_Right_add_Ghedest',\
	'Combined_Mean_G','Averaged_Mean_G','Averaged_Mean_D','Averaged_Mean_Gest','Averaged_Mean_Dest','Averaged_Mean_Ghedest']

	# Write out the title
	for i in range(len(outputtitle)-1):
		outputfile.write(outputtitle[i])
		outputfile.write(',')
	# To get return character on the end
	outputfile.write(str(outputtitle[len(outputtitle)-1])+'\n')	
	
	# Create a row of -9999
	novalue = np.zeros(69)
	
	# Write to file
	for i in range(n):		
		if not np.isnan(abundance_mean[i]):
			outputfile.write(str(i+1)+',')
			outputfile.write(str(float(X[i]))+',')
			outputfile.write(str(float(Y[i]))+',')
			outputfile.write(str(He_mean[i])+',')
			outputfile.write(str(He_left[i])+',')
			outputfile.write(str(He_right[i])+',')
			outputfile.write(str(A_mean[i])+',')
			outputfile.write(str(A_left[i])+',')
			outputfile.write(str(A_right[i])+',')
			outputfile.write(str(F_mean[i])+',')
			outputfile.write(str(F_left[i])+',')
			outputfile.write(str(F_right[i])+',')
			outputfile.write(str(deltaF_mean[i])+',')
			outputfile.write(str(deltaF_left[i])+',')
			outputfile.write(str(deltaF_right[i])+',')
			outputfile.write(str(D_mean[i])+',')
			outputfile.write(str(D_left[i])+',')
			outputfile.write(str(D_right[i])+',')
			outputfile.write(str(deltaD_mean[i])+',')
			outputfile.write(str(deltaD_left[i])+',')
			outputfile.write(str(deltaD_right[i])+',')
			outputfile.write(str(Fun_mean[i])+',')
			outputfile.write(str(Fun_left[i])+',')
			outputfile.write(str(Fun_right[i])+',')
			outputfile.write(str(deltaFun_mean[i])+',')
			outputfile.write(str(deltaFun_left[i])+',')
			outputfile.write(str(deltaFun_right[i])+',')
			outputfile.write(str(Dun_mean[i])+',')
			outputfile.write(str(Dun_left[i])+',')
			outputfile.write(str(Dun_right[i])+',')
			outputfile.write(str(deltaDun_mean[i])+',')
			outputfile.write(str(deltaDun_left[i])+',')
			outputfile.write(str(deltaDun_right[i])+',')
			outputfile.write(str(Gun_mean[i])+',')
			outputfile.write(str(Gun_left[i])+',')
			outputfile.write(str(Gun_right[i])+',')
			outputfile.write(str(deltaGun_mean[i])+',')
			outputfile.write(str(deltaGun_left[i])+',')
			outputfile.write(str(deltaGun_right[i])+',')
			outputfile.write(str(abundance_mean[i])+',')
			outputfile.write(str(abundance_left[i])+',')
			outputfile.write(str(abundance_right[i])+',')
			outputfile.write(str(Nm_mean[i])+',')
			outputfile.write(str(Nm_left[i])+',')
			outputfile.write(str(Nm_right[i])+',')		
			outputfile.write(str(deltaAbund_mean[i])+',')
			outputfile.write(str(deltaAbund_left[i])+',')
			outputfile.write(str(deltaAbund_right[i])+',')
			outputfile.write(str(weightDvalues_mean[i])+',')
			outputfile.write(str(weightDvalues_left[i])+',')
			outputfile.write(str(weightDvalues_right[i])+',')
			outputfile.write(str(weightGvalues_meanF[i])+',')
			outputfile.write(str(weightGvalues_leftF[i])+',')
			outputfile.write(str(weightGvalues_rightF[i])+',')
			outputfile.write(str(weightGvalues_meanD[i])+',')
			outputfile.write(str(weightGvalues_leftD[i])+',')
			outputfile.write(str(weightGvalues_rightD[i])+',')
			outputfile.write(str(weightGvalues_meanFun[i])+',')
			outputfile.write(str(weightGvalues_leftFun[i])+',')
			outputfile.write(str(weightGvalues_rightFun[i])+',')
			outputfile.write(str(weightGvalues_meanDun[i])+',')
			outputfile.write(str(weightGvalues_leftDun[i])+',')
			outputfile.write(str(weightGvalues_rightDun[i])+',')
			outputfile.write(str(weightGvalues_meanGun[i])+',')
			outputfile.write(str(weightGvalues_leftGun[i])+',')
			outputfile.write(str(weightGvalues_rightGun[i])+',')
			outputfile.write(str(combinedF[i])+',')
			outputfile.write(str(averagedF[i])+',')
			outputfile.write(str(averagedD[i])+',')
			outputfile.write(str(averagedFun[i])+',')
			outputfile.write(str(averagedDun[i])+',')	
			outputfile.write(str(averagedGun[i])+'\n')
	# Write out 0 and 3 for GIS output
	outputfile.write(str(n+1)+',')
	outputfile.write('0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n')
	outputfile.write(str(n+2)+',')
	outputfile.write('0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,3.0,0.0,0.0,3.0,0.0,0.0,3.0,0.0,0.0,3.0,0.0,0.0,3.0,0.0,0.0,3.0,0.0,0.0,3.0,0.0,0.0,3.0,3.0,3.0,3.0,3.0,3.0\n')
	
	print '\n'
	print 'The file has been created', outdir+'vuln_summary'+str(gen[igen])
				
	# Close file
	outputfile.close()	

	# Store differentiation and abundance values in temp location for previous generation to get change
	if igen == 0:
		
		F0_mean = F_mean
		F0_right = F_right
		F0_left = F_left
		D0_mean = D_mean
		D0_right = D_right
		D0_left = D_left
		Fun0_mean = Fun_mean
		Fun0_right = Fun_right
		Fun0_left = Fun_left
		Dun0_mean = Dun_mean
		Dun0_right = Dun_right
		Dun0_left = Dun_left
		Gun0_mean = Gun_mean
		Gun0_right = Gun_right
		Gun0_left = Gun_left
		# Here replace the NAN with 1s for the delta values....
		F0_mean = np.asarray(F0_mean)
		F0_right = np.asarray(F0_right)
		F0_left = np.asarray(F0_left)
		D0_mean = np.asarray(D0_mean)
		D0_right = np.asarray(D0_right)
		D0_left = np.asarray(D0_left)
		Fun0_mean = np.asarray(Fun0_mean)
		Fun0_right = np.asarray(Fun0_right)
		Fun0_left = np.asarray(Fun0_left)
		Dun0_mean = np.asarray(Dun0_mean)
		Dun0_right = np.asarray(Dun0_right)
		Dun0_left = np.asarray(Dun0_left)
		Gun0_mean = np.asarray(Gun0_mean)
		Gun0_right = np.asarray(Gun0_right)
		Gun0_left = np.asarray(Gun0_left)
		
		F0_mean[np.isnan(F0_mean)==True] = 1.0
		F0_right[np.isnan(F0_right)==True] = 1.0
		F0_left[np.isnan(F0_left) == True] = 1.0
		D0_mean[np.isnan(D0_mean) == True] = 1.0
		D0_right[np.isnan(D0_right) == True] = 1.0
		D0_left[np.isnan(D0_left) == True] = 1.0
		Fun0_mean[np.isnan(Fun0_mean) == True] = 1.0
		Fun0_right[np.isnan(Fun0_right) == True] = 1.0
		Fun0_left[np.isnan(Fun0_left) == True] = 1.0
		Dun0_mean[np.isnan(Dun0_mean) == True] = 1.0
		Dun0_right[np.isnan(Dun0_right) == True] = 1.0
		Dun0_left[np.isnan(Dun0_left) == True] = 1.0
		Gun0_mean[np.isnan(Gun0_mean) == True] = 1.0
		Gun0_right[np.isnan(Gun0_right) == True] = 1.0
		Gun0_left[np.isnan(Gun0_left) == True] = 1.0
		
		abund0_mean = abundance_mean
		abund0_right = abundance_right
		abund0_left = abundance_left
		abund0_mean = np.asarray(abund0_mean)
		abund0_right = np.asarray(abund0_right)
		abund0_left = np.asarray(abund0_left)
		# Here replace the NAN with 0s for the dleta values	
		abund0_mean[np.isnan(abund0_mean)==True] = 0.0
		abund0_right[np.isnan(abund0_right)==True] = 0.0
		abund0_left[np.isnan(abund0_left)==True] = 0.0
		
